@article{chewi2021rejection,
  title={Rejection sampling from shape-constrained distributions in sublinear time},
  author={Chewi, Sinho and Gerber, Patrik and Lu, Chen and Gouic, Thibaut Le and Rigollet, Philippe},
  journal={AISTATS},
  abstract={We consider the task of generating exact samples from a target distribution, known up to normalization, over a finite alphabet. The classical algorithm for this task is rejection sampling, and although it has been used in practice for decades, there is surprisingly little study of its fundamental limitations. In this work, we study the query complexity of rejection sampling in a minimax framework for various classes of discrete distributions. Our results provide new algorithms for sampling whose complexity scales sublinearly with the alphabet size. When applied to adversarial bandits, we show that a slight modification of the Exp3 algorithm reduces the per-iteration complexity from O(K) to O(log^2 K), where K is the number of arms.},
  year={2022},
  arxiv="2105.14166"
}

@article{altschuler2021averaging,
  title={Averaging on the Bures-Wasserstein manifold: dimension-free convergence of gradient descent},
  author={Altschuler, Jason M and Chewi, Sinho and Gerber, Patrik and Stromme, Austin J},
  journal={NeurIPS, Spotlight},
  year={2021},
  howpublished="\url{https://arxiv.org/pdf/2106.08502.pdf}",
  abstract={We study first-order optimization algorithms for computing the barycenter of Gaussian distributions with respect to the optimal transport metric. Although the objective is geodesically non-convex, Riemannian GD empirically converges rapidly, in fact faster than off-the-shelf methods such as Euclidean GD and SDP solvers. This stands in stark contrast to the best-known theoretical results for Riemannian GD, which depend exponentially on the dimension. In this work, we prove new geodesic convexity results which provide stronger control of the iterates, yielding a dimension-free convergence rate. Our techniques also enable the analysis of two related notions of averaging, the entropically-regularized barycenter and the geometric median, providing the first convergence guarantees for Riemannian GD for these problems.},
  arxiv="2106.08502"

}

@article{chewi2021query,
  title={The query complexity of sampling from strongly log-concave distributions in one dimension},
  author={Chewi, Sinho and Gerber, Patrik and Lu, Chen and Gouic, Thibaut Le and Rigollet, Philippe},
  journal={COLT},
  year={2022)},
  abstract={We establish the first tight lower bound of \Omega(loglog\kappa) on the query complexity of sampling from the class of strongly log-concave and log-smooth distributions with condition number \kappa &nbsp; in one dimension. Whereas existing guarantees for MCMC-based algorithms scale polynomially in \kappa, we introduce a novel algorithm based on rejection sampling that closes this doubly exponential gap.},
  arxiv="2105.14163"
}

@article{chewi2021gaussian,
  title={Gaussian discrepancy: a probabilistic relaxation of vector balancing},
  author={Chewi, Sinho and Gerber, Patrik and Rigollet, Philippe and Turner, Paxton},
  journal={Discrete Applied Mathematics},
  year={2022},
  abstract={We introduce a novel relaxation of combinatorial discrepancy called Gaussian discrepancy, whereby binary signings are replaced with correlated standard Gaussian random variables. This relaxation effectively reformulates an optimization problem over the Boolean hypercube into one over the space of correlation matrices. We show that Gaussian discrepancy is a tighter relaxation than the previously studied vector and spherical discrepancy problems, and we construct a fast online algorithm that achieves a version of the Banaszczyk bound for Gaussian discrepancy. This work also raises new questions such as the Komlo ÃÅs conjecture for Gaussian discrepancy, which may shed light on classical discrepancy problems.},
  arxiv="2109.08280"
}
