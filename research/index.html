<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title> | Research</title>
  <meta name="description" content="">





  <link rel="shortcut icon" href="https://patrikgerber.github.io/assets/img/favicon.ico">

  <link rel="stylesheet" href="https://patrikgerber.github.io/assets/css/main.css">
  <link rel="canonical" href="https://patrikgerber.github.io/research/">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">


    <span class="site-title">

        <!-- <strong></strong>  -->

    </span>


    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewbox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"></path>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"></path>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="https://patrikgerber.github.io/">About</a>

        <!-- Blog -->
        <!-- <a class="page-link" href="https://patrikgerber.github.io/blog/">blog</a> -->

        <!-- Pages -->
        <!-- Delete page.title != "publications" (etc) to get back other pages in the header -->










            <a class="page-link" href="https://patrikgerber.github.io/research/">Research</a>





            <a class="page-link" href="https://patrikgerber.github.io/teaching/">Teaching</a>











        <!-- CV link -->
        <!-- <a class="page-link" href="https://patrikgerber.github.io/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Research</h1>
    <h5 class="post-description"></h5>
  </header>

  <article class="post-content Research clearfix">
    <!-- <div>

</div> -->

<div>
  <ol class="bibliography">

    <li>
    <div id="gerberpoly">

        <span class="title">Likelihood-free hypothesis testing</span>
        <span class="author"><em>Patrik R√≥bert Gerber</em> and Yury Polyanskiy</span>

        <span class="periodical"><em>arXiv:2211.01126</em> (2022)
        </span>


      <span class="links">
        [<a href="#gerberpoly_abstract" class="abstract">abstract</a>]
        [<a href="https://arxiv.org/abs/2211.01126" target="_blank" rel="noopener noreferrer">arXiv</a>]
      </span>

      <!-- Hidden abstract block -->

      <span id="gerberpoly_abstract" class="abstract hidden">
        <p>Consider the problem of testing Z ~ ‚Ñô·µê vs Z ~ ‚Ñö·µê from m samples. Generally, to achieve a small error rate it is necessary and sufficient to have m‚âç1/œµ¬≤, where œµ measures the separation between ‚Ñô and ‚Ñö in total variation (ùñ≥ùñµ). Achieving this, however, requires complete knowledge of the distributions ‚Ñô and ‚Ñö and can be done, for example, using the Neyman-Pearson test. In this paper we consider a variation of the problem, which we call likelihood-free (or simulation-based) hypothesis testing, where access to ‚Ñô and ‚Ñö (which are a priori only known to belong to a large non-parametric family P) is given through n iid samples from each. We demostrate existence of a fundamental trade-off between n and m given by nm ‚âç n¬≤_ùñ¶ùóàùñ•(œµ,P), where n_ùñ¶ùóàùñ• is the minimax sample complexity of testing between the hypotheses H‚ÇÄ: ‚Ñô=‚Ñö vs H‚ÇÅ: ùñ≥ùñµ(‚Ñô,‚Ñö)‚â•œµ. We show this for three non-parametric families P: Œ≤-smooth densities over [0,1]d, the Gaussian sequence model over a Sobolev ellipsoid, and the collection of distributions P on a large alphabet [k] with pmfs bounded by c/k for fixed c. The test that we propose (based on the L¬≤-distance statistic of Ingster) simultaneously achieves all points on the tradeoff curve for these families. In particular, when m‚â´1/œµ¬≤ our test requires the number of simulation samples n to be orders of magnitude smaller than what is needed for density estimation with accuracy ‚âçœµ (under ùñ≥ùñµ). This demonstrates the possibility of testing without fully estimating the distributions.</p>
      </span>

    </div>
    </li>





<li>
<div id="chewi2022fisher">

    <span class="title">Fisher information lower bounds for sampling</span>
    <span class="author">Sinho Chewi, <em>Patrik R√≥bert Gerber</em>, Holden Lee and Chen Lu</span>

    <span class="periodical"><em>arXiv:2210.02482</em> (2022)
    </span>


  <span class="links">
    [<a href="#chewi2022fisher_abstract" class="abstract">abstract</a>]
    [<a href="https://arxiv.org/abs/2210.02482" target="_blank" rel="noopener noreferrer">arXiv</a>]
  </span>

  <!-- Hidden abstract block -->

  <span id="chewi2022fisher_abstract" class="abstract hidden">
    <p>We prove two lower bounds for the complexity of non-log-concave sampling within the framework of Balasubramanian et al. (2022), who introduced the use of Fisher information (FI) bounds as a notion of approximate first-order stationarity in sampling. Our first lower bound shows that averaged LMC is optimal for the regime of large FI by reducing the problem of finding stationary points in non-convex optimization to sampling. Our second lower bound shows that in the regime of small FI, obtaining a FI of at most Œµ¬≤ from the target distribution requires poly(1/Œµ) queries, which is surprising as it rules out the existence of high-accuracy algorithms (e.g., algorithms using Metropolis-Hastings filters) in this context.</p>
  </span>

</div>
</li>



<li>
<div id="chewi2021query">

    <span class="title">The query complexity of sampling from strongly log-concave distributions in one dimension</span>
    <span class="author">Sinho Chewi, <em>Patrik R√≥bert Gerber</em>, Chen Lu, Thibaut Le Gouic and Philippe Rigollet</span>

    <span class="periodical"><em>COLT</em> (2022)
    </span>


  <span class="links">
    [<a href="#chewi2021query_abstract" class="abstract">abstract</a>]
    [<a href="http://arxiv.org/abs/2105.14163" target="_blank" rel="noopener noreferrer">arXiv</a>]
  </span>

  <!-- Hidden abstract block -->

  <span id="chewi2021query_abstract" class="abstract hidden">
    <p>We establish the first tight lower bound of Œ©(loglogŒ∫) on the query complexity of sampling from the class of strongly log-concave and log-smooth distributions with condition number Œ∫¬† in one dimension. Whereas existing guarantees for MCMC-based algorithms scale polynomially in Œ∫, we introduce a novel algorithm based on rejection sampling that closes this doubly exponential gap.</p>
  </span>

</div>
</li>


<li>
<div id="chewi2021rejection">

    <span class="title">Rejection sampling from shape-constrained distributions in sublinear time</span>
    <span class="author">Sinho Chewi, <em>Patrik R√≥bert Gerber</em>, Chen Lu, Thibaut Le Gouic and Philippe Rigollet</span>

    <span class="periodical"><em>AISTATS</em> (2022)</span>


  <span class="links">
    [<a href="#chewi2021rejection_abstract" class="abstract">abstract</a>]
    [<a href="http://arxiv.org/abs/2105.14166" target="_blank" rel="noopener noreferrer">arXiv</a>]
  </span>

  <!-- Hidden abstract block -->
  <span id="chewi2021rejection_abstract" class="abstract hidden">
    <p>We consider the task of generating exact samples from a target distribution, known up to normalization, over a finite alphabet. The classical algorithm for this task is rejection sampling, and although it has been used in practice for decades, there is surprisingly little study of its fundamental limitations. In this work, we study the query complexity of rejection sampling in a minimax framework for various classes of discrete distributions. Our results provide new algorithms for sampling whose complexity scales sublinearly with the alphabet size. When applied to adversarial bandits, we show that a slight modification of the Exp3 algorithm reduces the per-iteration complexity from O(K) to O(log¬≤K), where K is the number of arms.</p>
  </span>

</div>
</li>


<li>
<div id="chewi2021gaussian">
    <span class="title">Gaussian discrepancy: a probabilistic relaxation of vector balancing</span>
    <span class="author">Sinho Chewi, <em>Patrik R√≥bert Gerber</em>, Philippe Rigollet and Paxton Turner</span>

    <span class="periodical"> <em>Discrete Applied Mathematics</em> (2022)</span>


  <span class="links">
    [<a href="#chewi2021gaussian_abstract" class="abstract">abstract</a>]
    [<a href="http://arxiv.org/abs/2109.08280" target="_blank" rel="noopener noreferrer">arXiv</a>]
  </span>

  <!-- Hidden abstract block -->

  <span id="chewi2021gaussian_abstract" class="abstract hidden">
    <p>We introduce a novel relaxation of combinatorial discrepancy called Gaussian discrepancy, whereby binary signings are replaced with correlated standard Gaussian random variables. This relaxation effectively reformulates an optimization problem over the Boolean hypercube into one over the space of correlation matrices. We show that Gaussian discrepancy is a tighter relaxation than the previously studied vector and spherical discrepancy problems, and we construct a fast online algorithm that achieves a version of the Banaszczyk bound for Gaussian discrepancy. This work also raises new questions such as the Komlo ÃÅs conjecture for Gaussian discrepancy, which may shed light on classical discrepancy problems.</p>
  </span>

</div>
</li>


<li>
<div id="altschuler2021averaging">

    <span class="title">Averaging on the Bures-Wasserstein manifold: dimension-free convergence of gradient descent</span>
    <span class="author">Jason M Altschuler, Sinho Chewi, <em>Patrik R√≥bert Gerber</em> and Austin J Stromme </span>

    <span class="periodical"><em>NeurIPS, Spotlight</em> (2021)</span>


  <span class="links">
    [<a href="#altschuler2021averaging_abstract" class="abstract">abstract</a>]
    [<a href="http://arxiv.org/abs/2106.08502" target="_blank" rel="noopener noreferrer">arXiv</a>]
</span>

  <!-- Hidden abstract block -->

  <span id="altschuler2021averaging_abstract" class="abstract hidden">
    <p>We study first-order optimization algorithms for computing the barycenter of Gaussian distributions with respect to the optimal transport metric. Although the objective is geodesically non-convex, Riemannian GD empirically converges rapidly, in fact faster than off-the-shelf methods such as Euclidean GD and SDP solvers. This stands in stark contrast to the best-known theoretical results for Riemannian GD, which depend exponentially on the dimension. In this work, we prove new geodesic convexity results which provide stronger control of the iterates, yielding a dimension-free convergence rate. Our techniques also enable the analysis of two related notions of averaging, the entropically-regularized barycenter and the geometric median, providing the first convergence guarantees for Riemannian GD for these problems.</p>
  </span>

</div>
</li>

</ol>
</div>

<!-- ### notes
1. Discrete computational optimal transport (with Adam Block) <small>[<a href="https://patrikgerber.github.io/assets/pdf/Discrete_Optimal_Transport.pdf">pdf</a>]</small>
2. L1-regularized regression <small>[<a href="https://patrikgerber.github.io/assets/pdf/L1_regularized_regression.pdf">pdf</a>]</small>
3. Sparse PCA (with Sinho Chewi) <small>[<a href="https://patrikgerber.github.io/assets/pdf/sparse_PCA.pdf">pdf</a>]</small> -->

<!-- ### presentations
1. Malliavin Calculus <small>[<a href="https://patrikgerber.github.io/assets/pdf/Malliavin_calculus.pdf">pdf</a>]</small>
2. Kernel density estimation via diffusion <small>[<a href="https://patrikgerber.github.io/assets/pdf/Kernel_density_estimation_via_Diffusion.pdf">pdf</a>]</small>
3. Normality testing via Wasserstein distance <small>[<a href="https://patrikgerber.github.io/assets/pdf/normality_testing.pdf">pdf</a>]</small>
4. The East-process <small>[<a href="https://github.com/PatrikGerber/East-process/blob/master/East_process_presentation.pdf">pdf</a>]</small>
5. Branching random walks with selection <small>[<a href="https://github.com/PatrikGerber/BRWs/blob/master/presentation.pdf">pdf</a>]</small>

### miscellaneous
1. I participated in <a href="https://www.ipam.ucla.edu/programs/student-research-programs/research-in-industrial-projects-for-students-rips-2020/?tab=faq">RIPS</a> where I worked on deep reinforcement learning sponsored by AMD <small>[<a href="https://github.com/AMD-RIPS/RL-2018/blob/master/documents/arxiv/AMDFinalReportRIPS2018.pdf">pdf</a>] [<a href="https://github.com/AMD-RIPS/RL-2018">code</a>]</small>
2. I spent a summer in the Statistics department of University of Oxford working on interacting particle systems under the supervision of Professor Paul Chleboun <small>[<a href="https://github.com/PatrikGerber/East-process/blob/master/East_process.pdf">pdf</a>]</small>
3. I wrote a master's thesis on branching random walks with selection, supervised by Professor Julien Berestycki <small>[<a href="https://github.com/PatrikGerber/BRWs/blob/master/FINAL/final_version.pdf">pdf</a>]</small> -->


</article>





</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    ¬© Copyright 2022 .
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.


        Last updated: November 3 2022.


<a class="icon" href="mailto:%70%72%67%65%72%62%65%72@%6D%69%74.%65%64%75"><i class="fas fa-envelope" style="font-size: 14px"></i></a>
    <!--  -->
    <a class="icon" href="https://scholar.google.com/citations?user=kB9AcDEAAAAJ" target="_blank" title="Google Scholar" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>
    <!--  -->
    <!--  -->
    <a class="icon" href="https://github.com/PatrikGerber" target="_blank" title="GitHub" rel="noopener noreferrer"><i class="fab fa-github" style="font-size: 14px"></i></a>
    <a class="icon" href="https://www.linkedin.com/in/patrik-robert-gerber" target="_blank" title="LinkedIn" rel="noopener noreferrer"><i class="fab fa-linkedin" style="font-size: 14px"></i></a>
    <!--  -->
    <!--  -->
    <!--  -->
    <!--  -->
    <!--  -->
</div>
</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-.min.js"></script>

<!-- Load Common JS -->
<script src="https://patrikgerber.github.io/assets/js/common.js"></script>





<!-- Include custom icon fonts -->
<link rel="stylesheet" href="https://patrikgerber.github.io/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="https://patrikgerber.github.io/assets/css/academicons.min.css">


<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-142179739-1', 'auto');
ga('send', 'pageview');
</script>



  </body>

</html>
